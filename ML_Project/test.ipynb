{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import tldextract\n",
    "import urllib.parse\n",
    "import requests\n",
    "import re\n",
    "import whois\n",
    "from datetime import datetime\n",
    "import streamlit as st\n",
    "import torch   \n",
    "from transformers import BertForSequenceClassification , BertTokenizerFast , pipeline\n",
    "\n",
    "prediction = 1\n",
    "\n",
    "def extract_domain(url):\n",
    "    return urllib.parse.urlparse(url).netloc\n",
    "\n",
    "def url_length(url):\n",
    "    return len(url)\n",
    "\n",
    "def subdomain_count(url):\n",
    "    domain_parts = extract_domain(url).split('.')\n",
    "    return len(domain_parts[:-2])\n",
    "\n",
    "def is_https(url):\n",
    "    return 1 if urllib.parse.urlparse(url).scheme == 'https' else 0\n",
    "\n",
    "def has_redirects(url):\n",
    "    try:\n",
    "        response = requests.get(url, allow_redirects=False, timeout=3)\n",
    "        return 1 if response.status_code in [301, 302, 303, 307, 308] else 0\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def count_suspicious_chars(url):\n",
    "    return len(re.findall('[@!$#%^&*()_+|~=`{}[\\]:/;<>?,.]', url))\n",
    "\n",
    "def path_length(url):\n",
    "    path = urllib.parse.urlparse(url).path\n",
    "    return len(path)\n",
    "\n",
    "def num_digits(url):\n",
    "    return sum(1 for c in url if c.isdigit())\n",
    "\n",
    "def num_digits_in_domain(url):\n",
    "    domain = extract_domain(url)\n",
    "    return sum(1 for c in domain if c.isdigit())\n",
    "\n",
    "def num_question_marks(url):\n",
    "    return url.count('?')\n",
    "\n",
    "def num_hyphen_in_domain(url):\n",
    "    domain = extract_domain(url)\n",
    "    return domain.count('-')\n",
    "\n",
    "def tld_in_subdomain(url):\n",
    "    extracted = tldextract.extract(url)\n",
    "    subdomain = extracted.subdomain\n",
    "    tld = extracted.suffix\n",
    "    return 1 if tld in subdomain else 0\n",
    "\n",
    "def num_at_symbols(url):\n",
    "    return url.count('@')\n",
    "\n",
    "def num_equals_symbols(url):\n",
    "    return url.count('=')\n",
    "\n",
    "def num_ampersand_symbols(url):\n",
    "    return url.count('&')\n",
    "\n",
    "def get_domain_age(domain):\n",
    "    try:\n",
    "        w = whois.whois(domain)\n",
    "        creation_date = w.creation_date\n",
    "        if isinstance(creation_date, list):\n",
    "            creation_date = creation_date[0]\n",
    "        now = datetime.now()\n",
    "        age = (now - creation_date).days\n",
    "        return age\n",
    "    except Exception as e:\n",
    "        return -1\n",
    "\n",
    "def rfb_model(x):\n",
    "    loaded_model = pickle.load(open(\"/Users/mahmoudmohamed/Downloads/project v2/new_random_forest_model.sav\", 'rb'))\n",
    "    prediction = loaded_model.predict(x)\n",
    "    return prediction\n",
    "\n",
    "def logistic_model(x):\n",
    "    loaded_model = pickle.load(open(\"/Users/mahmoudmohamed/Downloads/project v2/new_logistic_regression_model.sav\", 'rb'))\n",
    "    prediction = loaded_model.predict(x)\n",
    "    return prediction\n",
    "\n",
    "def svc_model(x):\n",
    "    loaded_model = pickle.load(open(\"/Users/mahmoudmohamed/Downloads/project v2/new_SVC_model.sav\", 'rb'))\n",
    "    prediction = loaded_model.predict(x)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "# Bert Model \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_path = \"CrabInHoney/urlbert-tiny-v2-phishing-classifier\"\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"URL Detection System\")\n",
    "\n",
    "url = st.text_input(\"Enter URL\", placeholder=\"https://example.com\")\n",
    "model_choice = st.selectbox(\"Select Model\", [\"Random forest model\", \"Logistic regression model\", \"Support vector classifier\"])\n",
    "\n",
    "if st.button(\"Check URL\"):\n",
    "    if not url:\n",
    "        st.warning(\"Please enter a valid URL.\")\n",
    "    else:\n",
    "        domain = extract_domain(url)\n",
    "        tld_subdomain = tld_in_subdomain(url)\n",
    "        url_len = url_length(url)\n",
    "        redirect = has_redirects(url)\n",
    "        suspicious_chars = count_suspicious_chars(url)\n",
    "        num_digits_url = num_digits(url)\n",
    "        num_digits_domain = num_digits_in_domain(url)\n",
    "        num_question_marks_url = num_question_marks(url)\n",
    "        path_len = path_length(url)\n",
    "        domain_age = get_domain_age(domain)\n",
    "        num_hyphen = num_hyphen_in_domain(domain)\n",
    "        num_at = num_at_symbols(url)\n",
    "        num_equal = num_equals_symbols(url)\n",
    "        num_and = num_ampersand_symbols(url)\n",
    "\n",
    "        data = [{\n",
    "            'url_length': url_len, 'num_digits': num_digits_url, 'domain_age': domain_age,\n",
    "            'count_suspicious_chars': suspicious_chars, 'path_length': path_len,\n",
    "            'num_digits_in_domain': num_digits_domain, 'num_?': num_question_marks_url,\n",
    "            'has_redirects': redirect, 'num_hyphen_domain': num_hyphen,\n",
    "            'tld_in_subdomain': tld_subdomain, 'num_@': num_at,\n",
    "            'num_=': num_equal, 'num_&': num_and\n",
    "        }]\n",
    "\n",
    "        x = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "        if model_choice == \"Random forest model\":\n",
    "            prediction = rfb_model(x)[0]\n",
    "        elif model_choice == \"Logistic regression model\":\n",
    "            prediction = logistic_model(x)[0]\n",
    "        elif model_choice == \"Support vector classifier\":\n",
    "            prediction = svc_model(x)[0]\n",
    "\n",
    "        elif model_choice == \"Bert model\":\n",
    "            result = classifier(url)\n",
    "            print(result)\n",
    "\n",
    "\n",
    "        print(prediction)\n",
    "\n",
    "        if prediction == 1:\n",
    "            st.success(\"The entered URL is real.\")\n",
    "        else:\n",
    "            st.error(\"The entered URL is fake.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
